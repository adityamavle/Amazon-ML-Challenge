{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityamavle/Amazon-ML-Challenge/blob/main/AmazonChallenge23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Imports"
      ],
      "metadata": {
        "id": "KUgpYYUAqk6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9iYZPR6BMI6",
        "outputId": "157ad467-bfc4-48f6-e087-1f14c091e81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-22 12:18:32--  https://s3-ap-southeast-1.amazonaws.com/he-public-data/datasetb2d9982.zip\n",
            "Resolving s3-ap-southeast-1.amazonaws.com (s3-ap-southeast-1.amazonaws.com)... 52.219.128.134\n",
            "Connecting to s3-ap-southeast-1.amazonaws.com (s3-ap-southeast-1.amazonaws.com)|52.219.128.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 895569552 (854M) [binary/octet-stream]\n",
            "Saving to: ‘AmazonChallenge23Dataset’\n",
            "\n",
            "AmazonChallenge23Da 100%[===================>] 854.08M  14.5MB/s    in 63s     \n",
            "\n",
            "2023-04-22 12:19:35 (13.6 MB/s) - ‘AmazonChallenge23Dataset’ saved [895569552/895569552]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "!wget https://s3-ap-southeast-1.amazonaws.com/he-public-data/datasetb2d9982.zip -O AmazonChallenge23Dataset\n",
        "zip_ref = zipfile.ZipFile(\"AmazonChallenge23Dataset\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xX5Wp0wCCE0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv(\"/content/dataset/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "XqeyUqMqDQZ6",
        "outputId": "3fc6d48d-0005-4593-9d08-681fa66a4548"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-654a2161-ceb5-40b0-9e7b-82a610c55f41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1925202</td>\n",
              "      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n",
              "      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1650</td>\n",
              "      <td>2125.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2673191</td>\n",
              "      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n",
              "      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2755</td>\n",
              "      <td>393.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2765088</td>\n",
              "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
              "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
              "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
              "      <td>7537</td>\n",
              "      <td>748.031495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1594019</td>\n",
              "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
              "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
              "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
              "      <td>2996</td>\n",
              "      <td>787.401574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>283658</td>\n",
              "      <td>The United Empire Loyalists: A Chronicle of th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6112</td>\n",
              "      <td>598.424000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-654a2161-ceb5-40b0-9e7b-82a610c55f41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-654a2161-ceb5-40b0-9e7b-82a610c55f41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-654a2161-ceb5-40b0-9e7b-82a610c55f41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   PRODUCT_ID                                              TITLE  \\\n",
              "0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n",
              "1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n",
              "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
              "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
              "4      283658  The United Empire Loyalists: A Chronicle of th...   \n",
              "\n",
              "                                       BULLET_POINTS  \\\n",
              "0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n",
              "1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n",
              "2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
              "3  [Made By 95%cotton and 5% Lycra which gives yo...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
              "0                                                NaN             1650   \n",
              "1                                                NaN             2755   \n",
              "2  Specifications: Color: Red, Material: Aluminiu...             7537   \n",
              "3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
              "4                                                NaN             6112   \n",
              "\n",
              "   PRODUCT_LENGTH  \n",
              "0     2125.980000  \n",
              "1      393.700000  \n",
              "2      748.031495  \n",
              "3      787.401574  \n",
              "4      598.424000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "ErZ6CqrsEQQZ",
        "outputId": "48679214-bc9b-4689-b019-89343affa008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-0bc27f030cd9>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  train.corr()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b16116f8-7d38-4986-b702-efafd54be234\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250576</td>\n",
              "      <td>0.000424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <td>0.250576</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "      <td>0.000424</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b16116f8-7d38-4986-b702-efafd54be234')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b16116f8-7d38-4986-b702-efafd54be234 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b16116f8-7d38-4986-b702-efafd54be234');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 PRODUCT_ID  PRODUCT_TYPE_ID  PRODUCT_LENGTH\n",
              "PRODUCT_ID         1.000000         0.250576        0.000424\n",
              "PRODUCT_TYPE_ID    0.250576         1.000000        0.000961\n",
              "PRODUCT_LENGTH     0.000424         0.000961        1.000000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuB-wBwAJRDg"
      },
      "source": [
        "### Imputing null values in bullet points and description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Y3sPd9M51_0z",
        "outputId": "a8cc9d05-8897-4cdd-be84-e4ad27120da3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a1138cad-bd7e-409e-bdde-8a0cd8ea1caf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>18716</td>\n",
              "      <td>In Defense of Globalization</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In Defense of Globalization [Hardcover] [Jan 0...</td>\n",
              "      <td>115</td>\n",
              "      <td>787.400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>9365</td>\n",
              "      <td>Virology: A Laboratory Manual (Instructor's Ma...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6264</td>\n",
              "      <td>850.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>14599</td>\n",
              "      <td>Henry V</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>113</td>\n",
              "      <td>507.873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>1826</td>\n",
              "      <td>2023 Guide to the Night Sky: A month-by-month ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6142</td>\n",
              "      <td>582.676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>6460</td>\n",
              "      <td>Office Management</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75</td>\n",
              "      <td>129.921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1138cad-bd7e-409e-bdde-8a0cd8ea1caf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1138cad-bd7e-409e-bdde-8a0cd8ea1caf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1138cad-bd7e-409e-bdde-8a0cd8ea1caf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      PRODUCT_ID                                              TITLE  \\\n",
              "298        18716                        In Defense of Globalization   \n",
              "857         9365  Virology: A Laboratory Manual (Instructor's Ma...   \n",
              "872        14599                                            Henry V   \n",
              "971         1826  2023 Guide to the Night Sky: A month-by-month ...   \n",
              "1168        6460                                  Office Management   \n",
              "\n",
              "     BULLET_POINTS                                        DESCRIPTION  \\\n",
              "298            NaN  In Defense of Globalization [Hardcover] [Jan 0...   \n",
              "857            NaN                                                NaN   \n",
              "872            NaN                                                NaN   \n",
              "971            NaN                                                NaN   \n",
              "1168           NaN                                                NaN   \n",
              "\n",
              "      PRODUCT_TYPE_ID  PRODUCT_LENGTH  \n",
              "298               115         787.400  \n",
              "857              6264         850.000  \n",
              "872               113         507.873  \n",
              "971              6142         582.676  \n",
              "1168               75         129.921  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train2 = train[(train[\"PRODUCT_ID\"] >= 0) & (train[\"PRODUCT_ID\"] <= 20000)]\n",
        "train2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7--F8mQ3W7C",
        "outputId": "23dc12bd-5a35-4645-d34b-b2fc2057634f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aPqD7ak7Jqi",
        "outputId": "973d0f84-fac3-41b0-f111-577e87fd6f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.9/dist-packages (from summa) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy>=0.19->summa) (1.22.4)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54408 sha256=46110b6731d2bf15e9646c71be44043f70270852d18667cf27aee9c7a27b01a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/2c/5f/a0ccc5955d44d2cea78729f4425e73f818d2629517f7af0f8b\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install summa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciUreo3I8F9x"
      },
      "outputs": [],
      "source": [
        "### Function to replace null values by null string in a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui6sX30E8d_h",
        "outputId": "498c7f66-4171-4add-ac0a-d6446311e8cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False    15037\n",
              "True         2\n",
              "Name: TITLE, dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train2['TITLE'].isna().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNysEqdGEKSK",
        "outputId": "589acebb-eca8-4ca4-9d15-88b1e597b030"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from summa import summarizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    # Tokenize text into words\n",
        "    tokens = word_tokenize(text)\n",
        "    # Filter out stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Join tokens back into text\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "def extract_keywords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    # Calculate term frequency\n",
        "    fdist = FreqDist(tokens)\n",
        "    keywords = [word for word, freq in fdist.items() if freq > 1]\n",
        "    return keywords\n",
        "\n",
        "def summarize(text):\n",
        "    summary = summarizer.summarize(text)\n",
        "    return summary\n",
        "for index, row in train2.iterrows():\n",
        "  if not pd.isnull(row['TITLE']):\n",
        "      title = row['TITLE']\n",
        "      title = remove_stopwords(title)\n",
        "      keywords = extract_keywords(title)\n",
        "      if pd.isnull(row['BULLET_POINTS']):\n",
        "          train2.at[index, 'BULLET_POINTS'] = ', '.join(keywords)\n",
        "      # Remove stop words from DESCRIPTION column\n",
        "      summary = summarize(title)\n",
        "      # Replace null values in DESCRIPTION column with generated summary\n",
        "      if pd.isnull(row['DESCRIPTION']):\n",
        "          train2.at[index, 'DESCRIPTION'] = summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRzEDiZo9Isp",
        "outputId": "59b96741-7957-4bc9-a013-4176cceb3a63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False    15037\n",
              "True         2\n",
              "Name: DESCRIPTION, dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train2['DESCRIPTION'].isna().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujqnj67C_0Df",
        "outputId": "30e8692f-857c-4fdb-bf44-84db5d6f8f9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2249698"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py6DQhnp_mrn",
        "outputId": "d85d8048-b3f7-4266-bf96-b4e79962eeb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DESCRIPTION  BULLET_POINTS  TITLE\n",
              "False        False          False    1038460\n",
              "True         True           False     783497\n",
              "             False          False     373872\n",
              "False        True           False      53857\n",
              "True         True           True          10\n",
              "             False          True           2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[['DESCRIPTION', 'BULLET_POINTS', 'TITLE']].isnull().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvC2ZDmHAwUu",
        "outputId": "09412604-80b1-4093-9913-2d304b3ac4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True     1157381\n",
            "False    1092317\n",
            "Name: DESCRIPTION, dtype: int64\n",
            "False    1412334\n",
            "True      837364\n",
            "Name: BULLET_POINTS, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train['DESCRIPTION'].isnull().value_counts())\n",
        "print(train['BULLET_POINTS'].isnull().value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqWpnLnCCTY9",
        "outputId": "8fd0108a-a6d4-4119-cfb8-0e05740523d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PRODUCT_ID               0\n",
              "TITLE                   12\n",
              "BULLET_POINTS       837364\n",
              "DESCRIPTION        1157381\n",
              "PRODUCT_TYPE_ID          0\n",
              "PRODUCT_LENGTH           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWy-o9Do_LJ4",
        "outputId": "a16ad719-b68a-4485-b9df-48dc2e10056a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with at least one column (DESCRIPTION, BULLET_POINTS, or TITLE) as null:  1211238\n"
          ]
        }
      ],
      "source": [
        "# Count the number of rows where at least one column (DESCRIPTION, BULLET_POINTS, or TITLE) is null\n",
        "null_rows = len(train[train[['DESCRIPTION', 'BULLET_POINTS', 'TITLE']].isnull().any(axis=1)])\n",
        "\n",
        "# Print the count of null rows\n",
        "print(\"Number of rows with at least one column (DESCRIPTION, BULLET_POINTS, or TITLE) as null: \", null_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNgc2HNN7uWa",
        "outputId": "0493af97-82bd-4776-d768-e8f69f06ddaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n",
            "<class 'float'>\n"
          ]
        }
      ],
      "source": [
        "for index, row in train2.iterrows():\n",
        "    # Remove stop words from TITLE column\n",
        "    desc = row['DESCRIPTION']\n",
        "    #print(title)\n",
        "    print(type(desc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgkYyK_r6fnL"
      },
      "outputs": [],
      "source": [
        "# Define summarization function\n",
        "def summarize(text):\n",
        "    # Tokenize text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    # Calculate sentence scores based on term frequency\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "    # Convert tfidf_matrix to dense array\n",
        "    tfidf_matrix_dense = tfidf_matrix.toarray()\n",
        "    # Calculate sentence scores using cosine distance\n",
        "    sentence_scores = []\n",
        "    for i in range(tfidf_matrix_dense.shape[0]):\n",
        "        for j in range(tfidf_matrix_dense.shape[0]):\n",
        "            if i != j:\n",
        "                sentence_scores.append(cosine_distance(tfidf_matrix_dense[i], tfidf_matrix_dense[j]))\n",
        "            else:\n",
        "                sentence_scores.append(0) # Setting similarity score to 0 for the same sentence\n",
        "    # Sort sentences by scores\n",
        "    sorted_indices = sorted(range(len(sentence_scores)), key=lambda x: sentence_scores[x])\n",
        "    # Select top sentences as summary\n",
        "    summary = [sentences[i] for i in sorted_indices[:5]]  # Select top 5 sentences as summary\n",
        "    return \" \".join(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q05cUOdqF7oT",
        "outputId": "98a15760-2001-40fb-d2cb-5f43a044d87f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1038460"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dropped = train.dropna()\n",
        "train_dropped.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqHxz299IHqJ"
      },
      "source": [
        "### Training a baseline distilbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN-IUtCqIUHh",
        "outputId": "ca105b2a-bbd8-4bc0-aa06-a866d140e4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yh9oTtjI6ah"
      },
      "outputs": [],
      "source": [
        "train_dropped = train.dropna()\n",
        "train_dropped = train_dropped.sample(n=10000,random_state=52)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqJfVR4vm3XP",
        "outputId": "aadde809-6f32-4dfe-f314-db2a66ea3101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_input_ids: (8000,)\n",
            "Shape of train_attention_masks: (8000,)\n",
            "Shape of train_labels: (8000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming train_input_ids, train_attention_masks, and train_labels are NumPy arrays\n",
        "\n",
        "# Check shape of train_input_ids\n",
        "print(\"Shape of train_input_ids:\", train_input_ids.shape)\n",
        "\n",
        "# Check shape of train_attention_masks\n",
        "print(\"Shape of train_attention_masks:\", train_attention_masks.shape)\n",
        "\n",
        "# Check shape of train_labels\n",
        "print(\"Shape of train_labels:\", train_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv2Gh8SXtQLR"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "max_length = 128\n",
        "max_seq_length = 128\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Step 2: Load and preprocess the dataset\n",
        "# Assume that the dataset is loaded into a pandas DataFrame called \"df\"\n",
        "# and that the \"bullet_points\" column contains the bullet points and \"product_length\" contains the label\n",
        "\n",
        "X = train_dropped['BULLET_POINTS'].tolist()\n",
        "y = train_dropped['PRODUCT_LENGTH'].values\n",
        "\n",
        "# Preprocess the bullet points using the tokenizer\n",
        "X_preprocessed = []\n",
        "for text in X:\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True,padding = 'max_length',max_length = max_length,truncation = True) #Truncation done\n",
        "    X_preprocessed.append(input_ids)\n",
        "    # Pad or truncate the input sequence to a fixed length\n",
        "    if len(input_ids) > max_seq_length:\n",
        "        input_ids = input_ids[:max_seq_length-1] + [tokenizer.sep_token_id]  # Truncate and add SEP token\n",
        "    else:\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aevh6X2GxFRG",
        "outputId": "62c8a483-d76e-4873-df85-8ef23c77e121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.CustomDataset object at 0x7fabb8854fd0>\n",
            "(8000, 200)\n"
          ]
        }
      ],
      "source": [
        "print(val_dataset)\n",
        "print(train_input_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5vk8rjZu_UH"
      },
      "outputs": [],
      "source": [
        "val_df['length'] = val_df['BULLET_POINTS'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nycFLygyvIvR",
        "outputId": "472f776c-7d75-4a86-f0ad-5540cfbd0d77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200    2000\n",
              "Name: length, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df['length'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwKcbFOauU9K",
        "outputId": "59939eb2-2c93-4a7e-ee1a-9c177e79277d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "736700     [101, 1031, 7427, 2443, 1024, 1015, 1060, 1294...\n",
            "91546      [101, 1031, 2715, 1011, 4906, 5413, 2080, 2460...\n",
            "44777      [101, 1031, 18546, 3756, 1049, 2575, 2581, 161...\n",
            "60815      [101, 1031, 2308, 1005, 1055, 3614, 1024, 1016...\n",
            "2197343    [101, 1031, 5308, 1997, 1017, 9132, 1010, 2946...\n",
            "                                 ...                        \n",
            "1101737    [101, 1031, 1026, 1038, 1028, 3430, 1026, 1013...\n",
            "737079     [101, 1031, 9381, 1011, 2184, 4960, 1010, 4578...\n",
            "1853848    [101, 1031, 4633, 1011, 6947, 1998, 2300, 1011...\n",
            "374178     [101, 1031, 1063, 7661, 2569, 9604, 1065, 1011...\n",
            "671268     [101, 1031, 3602, 1024, 1996, 10826, 3855, 268...\n",
            "Name: BULLET_POINTS, Length: 2000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(val_df['BULLET_POINTS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "vUqdJWdW0cGD",
        "outputId": "ce32dc3f-c8cf-45e2-a603-78f0783bb1f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-2530547439db>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         )\n\u001b[0;32m-> 1662\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1663\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# Handle dict or lists with proper padding and conversion to tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             batch = {\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2952\u001b[0m         \u001b[0;31m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2954\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2955\u001b[0m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
          ]
        }
      ],
      "source": [
        "class DistilBERTRegression(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTRegression, self).__init__()\n",
        "        self.distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "        self.linear = torch.nn.Linear(768, 1)  # 768 is the hidden size of DistilBERT\n",
        "\n",
        "    def forward(self, input_ids,attention_masks):\n",
        "        outputs = self.distilbert(input_ids)\n",
        "        pooled_output = outputs[0][:, 0]  # Extract the pooled output of the first token\n",
        "        prediction = self.linear(pooled_output)\n",
        "        return prediction.view(-1)\n",
        "\n",
        "# Instantiate the model\n",
        "model = DistilBERTRegression()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "output_dir='./results', # Directory for storing training outputs\n",
        "num_train_epochs=3, # Number of epochs for training\n",
        "per_device_train_batch_size=8, # Batch size for training\n",
        "per_device_eval_batch_size=8, # Batch size for evaluation\n",
        "save_steps=-1, # Number of steps to save model checkpoint\n",
        "save_total_limit=2, # Limit on the total number of saved checkpoints\n",
        "prediction_loss_only=True, # Compute only prediction loss, not other losses\n",
        "logging_dir='./logs', # Directory for storing logs\n",
        "logging_steps=500, # Number of steps for logging\n",
        "evaluation_strategy='epoch',\n",
        "save_strategy = 'epoch',\n",
        "load_best_model_at_end=True, # Load the best model at the end of training\n",
        "metric_for_best_model='eval_loss', # Metric for selecting the best model\n",
        "greater_is_better=False # Whether a greater value of the metric is better or not\n",
        ")\n",
        "# training_args = TrainingArguments(\n",
        "#     per_device_train_batch_size=8,  # Batch size for training\n",
        "#     num_train_epochs=3,  # Number of training epochs\n",
        "#     save_steps=-1,  # Number of steps between each save\n",
        "#     save_total_limit=2,  # Maximum number of saved checkpoints\n",
        "#     output_dir='./output',  # Directory to save the model\n",
        "#     overwrite_output_dir=True,  # Overwrite the output directory if it already exists\n",
        "#     logging_dir='./logs',  # Directory to save the logs\n",
        "#     logging_steps=500,  # Number of steps between each log\n",
        "#     evaluation_strategy='epoch',\n",
        "#     save_strategy = 'epoch',  # When to evaluate the model during training\n",
        "#     load_best_model_at_end=True,  # Load the best model at the end of training\n",
        "#     metric_for_best_model='eval_loss',  # Metric to determine the best model\n",
        "#     greater_is_better=False  # Smaller evaluation metric is better (since it's a regression problem)\n",
        "# )\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = p.predictions.flatten()\n",
        "  labels = p.label_ids.flatten()\n",
        "  return {\n",
        "  'mae': mean_absolute_error(labels, preds)\n",
        "  }\n",
        "\n",
        "#Create data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer)\n",
        "\n",
        "#Create Trainer\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  data_collator=data_collator,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=val_dataset,\n",
        "  compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "#Train the model\n",
        "trainer.train()\n",
        "\n",
        "#Evaluate the model\n",
        "eval_results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "print(f'Evaluation results: {eval_results}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fod6oszap_Dl",
        "outputId": "f23b3762-fa3b-4d26-9c9a-e0b8a4ac0344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_input_ids_padded: torch.Size([8000, 152])\n",
            "Shape of train_attention_masks_padded: torch.Size([8000, 152])\n",
            "Shape of val_input_ids_padded: torch.Size([2000, 155])\n",
            "Shape of val_attention_masks_padded: torch.Size([2000, 155])\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "# Convert numpy arrays to list of tensors\n",
        "train_input_ids_list = [torch.tensor(seq) for seq in train_input_ids]\n",
        "train_attention_masks_list = [torch.tensor(seq) for seq in train_attention_masks]\n",
        "\n",
        "# Pad sequences to the maximum length\n",
        "train_input_ids_padded = pad_sequence(train_input_ids_list, batch_first=True, padding_value=0)\n",
        "train_attention_masks_padded = pad_sequence(train_attention_masks_list, batch_first=True, padding_value=0)\n",
        "\n",
        "val_input_ids_list = [torch.tensor(seq) for seq in val_input_ids]\n",
        "val_attention_masks_list = [torch.tensor(seq) for seq in val_attention_masks]\n",
        "\n",
        "# Pad sequences to the maximum length\n",
        "val_input_ids_padded = pad_sequence(val_input_ids_list, batch_first=True, padding_value=0)\n",
        "val_attention_masks_padded = pad_sequence(val_attention_masks_list, batch_first=True, padding_value=0)\n",
        "# Verify the shapes of padded sequences\n",
        "print(\"Shape of train_input_ids_padded:\", train_input_ids_padded.shape)\n",
        "print(\"Shape of train_attention_masks_padded:\", train_attention_masks_padded.shape)\n",
        "val_input_ids_list = [torch.tensor(seq) for seq in val_input_ids]\n",
        "val_attention_masks_list = [torch.tensor(seq) for seq in val_attention_masks]\n",
        "\n",
        "# Pad sequences to the maximum length\n",
        "print(\"Shape of val_input_ids_padded:\", val_input_ids_padded.shape)\n",
        "print(\"Shape of val_attention_masks_padded:\", val_attention_masks_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNlRfLsG2bMJ",
        "outputId": "31dab5c0-65dd-4eaa-dcb9-6e4e590c62fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 200), (2000, 200))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_input_ids.shape,val_input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "Y6Fc5CgkGIXL",
        "outputId": "117327a9-90df-463c-f572-f104aa3c60d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-243367f0a142>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define a function to compute metrics during evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Visualize the metrics using Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         )\n\u001b[0;32m-> 1662\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1663\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2699\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2731\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You have to specify either input_ids or inputs_embeds"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EvalPrediction\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=1)#Regression problem,num_labels=1\n",
        "# Create a DistilBERT model\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,  # Batch size for training\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    save_steps=-1,  # Number of steps between each save\n",
        "    save_total_limit=2,  # Maximum number of saved checkpoints\n",
        "    output_dir='./output',  # Directory to save the model\n",
        "    overwrite_output_dir=True,  # Overwrite the output directory if it already exists\n",
        "    logging_dir='./logs',  # Directory to save the logs\n",
        "    logging_steps=500,  # Number of steps between each log\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy = 'epoch',  # When to evaluate the model during training\n",
        "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',  # Metric to determine the best model\n",
        "    greater_is_better=False  # Smaller evaluation metric is better (since it's a regression problem)\n",
        ")\n",
        "# class MyDataCollator(DataCollatorForLanguageModeling):\n",
        "#     def collate_batch(self, examples):\n",
        "#         if isinstance(examples[0], (list, tuple)):\n",
        "#             # If examples is a list of examples\n",
        "#             batch = super().collate_batch(examples)\n",
        "#         else:\n",
        "#             # If examples is a single example\n",
        "#             batch = {k: torch.unsqueeze(v, 0) for k, v in examples.items()}\n",
        "\n",
        "#         # Convert tensors to numpy arrays to avoid vars() error\n",
        "#         batch = {k: v.numpy() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "#         return batch\n",
        "# data_collator = MyDataCollator(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "#Create a Trainer instance\n",
        "def compute_metrics(eval_pred):\n",
        "     predictions = eval_pred.predictions.flatten()\n",
        "     labels = eval_pred.label_ids.flatten()\n",
        "     metrics = {\n",
        "         'mae': mean_absolute_error(labels, predictions)  # Mean Absolute Error\n",
        "     }\n",
        "     return metrics\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "# Define a function to compute metrics during evaluation\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Visualize the metrics using Tensorboard\n",
        "writer = SummaryWriter(log_dir='./logs')  # Create a SummaryWriter instance\n",
        "writer.add_scalar('Train Loss', trainer.train_dataloader.dataset.metrics['train_loss'].get_latest(), global_step=trainer.global_step)  # Log train loss\n",
        "writer.add_scalar('Eval Loss', trainer.eval_dataloader.dataset.metrics['eval_loss'].get_latest(), global_step=trainer.global_step)  # Log eval loss\n",
        "writer.add_scalar('MAE', trainer.eval_dataloader.dataset.metrics['mae'].get_latest(), global_step=trainer.global_step)  # Log MAE\n",
        "writer.flush()  # Flush the writer\n",
        "writer.close()  # Close the writer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CRcW-tj2ppJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx-b04QR2b14"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/dataset/train.csv')\n",
        "train_dropped = train.dropna()\n",
        "train_dropped = train_dropped.sample(n=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hoYZ3gYMRfJ"
      },
      "outputs": [],
      "source": [
        "del train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oo13yDzdKvE",
        "outputId": "9a0a6f92-1273-42fa-ad47-08577184befb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1626747    [101, 1031, 2440, 3417, 8782, 12997, 2015, 265...\n",
            "829528     [101, 1031, 2204, 3737, 1998, 7218, 2000, 2224...\n",
            "58698      [101, 1031, 4368, 2100, 7216, 2038, 2196, 2246...\n",
            "950472     [101, 1031, 1996, 4799, 3829, 15740, 2015, 202...\n",
            "2070671    [101, 1011, 9078, 12259, 17072, 1011, 19942, 4...\n",
            "                                 ...                        \n",
            "1513105    [101, 1031, 100, 6581, 3430, 100, 1024, 6065, ...\n",
            "805428     [101, 1031, 100, 2005, 4253, 1013, 25039, 2015...\n",
            "1511021    [101, 1031, 2023, 2630, 19392, 6556, 3084, 200...\n",
            "835328     [101, 1031, 18906, 4402, 8313, 1024, 7221, 540...\n",
            "458093     [101, 1037, 2460, 1010, 2898, 12073, 2003, 505...\n",
            "Name: BULLET_POINTS, Length: 2000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EvalPrediction\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "# Split the dataset into train and validation sets\n",
        "train_df, val_df = train_test_split(train_dropped, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "max_length = 50 #truncate and pad all to the same length\n",
        "def preprocess_text(text):\n",
        "    # Tokenize text\n",
        "    tokenized_text = tokenizer.encode(text, truncation=True, padding=\"max_length\", max_length=max_length)\n",
        "    if len(tokenized_text) < max_length:\n",
        "       tokenized_text += [tokenizer.pad_token_id] * (max_length - len(tokenized_text))\n",
        "    elif len(tokenized_text) > max_length:\n",
        "       tokenized_text = tokenized_text[:max_length]\n",
        "    return tokenized_text\n",
        "\n",
        "train_df['TITLE'] = train_df['TITLE'].apply(preprocess_text)\n",
        "train_df['DESCRIPTION'] = train_df['DESCRIPTION'].apply(preprocess_text)\n",
        "train_df['BULLET_POINTS'] = train_df['BULLET_POINTS'].apply(preprocess_text)\n",
        "val_df['TITLE'] = val_df['TITLE'].apply(preprocess_text)\n",
        "val_df['DESCRIPTION'] = val_df['DESCRIPTION'].apply(preprocess_text)\n",
        "val_df['BULLET_POINTS'] = val_df['BULLET_POINTS'].apply(preprocess_text)\n",
        "\n",
        "def create_input_tensors(df):\n",
        "    input_ids = np.array(df['TITLE'].tolist())\n",
        "    #attention_masks = np.array(df['TITLE'].apply(lambda x: [1] * len(x)).tolist())\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    attention_masks = np.array([[1 if token_id != tokenizer.pad_token_id else 0 for token_id in input_id] for input_id in input_ids])\n",
        "    labels = np.array(df['PRODUCT_LENGTH'].tolist())  #'PRODUCT_LENGTH':label\n",
        "\n",
        "    return input_ids, attention_masks, labels\n",
        "\n",
        "train_input_ids, train_attention_masks, train_labels = create_input_tensors(train_df)\n",
        "val_input_ids, val_attention_masks, val_labels = create_input_tensors(val_df)\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.input_ids[index], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.attention_masks[index], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.labels[index], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "# train_dataset = CustomDataset(train_input_ids_padded, train_attention_masks_padded, train_labels)\n",
        "# val_dataset = CustomDataset(val_input_ids_padded, val_attention_masks_padded, val_labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "val_dataset = CustomDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "print(val_df['BULLET_POINTS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt7F4TwvDzX5",
        "outputId": "5016e524-8ef9-40b3-917a-7e577720e4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([  101,  9805,  2213,  2078, 14030, 10140,  3336,  5061, 13383,\n",
              "         2005,  3057,  1011,  1019,  1048,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_input_ids[10],train_attention_masks[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VL9sfFR2RB5",
        "outputId": "0f17c6e2-1496-479f-bab4-7100f9798ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "S7OHlSNU6uMt",
        "outputId": "ce8618cc-f4d3-4b77-a7f1-6043953471cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-797fa5b85e04>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute loss # Problem is in the shape of predictions and self.Linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (200) must match the size of tensor b (16) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "\n",
        "# Define DistilBERT regression model\n",
        "class DistilBERTRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTRegression, self).__init__()\n",
        "        self.distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "        self.linear = nn.Linear(16,200)  # 768 is the hidden size of DistilBERT\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        outputs = self.distilbert(input_ids)\n",
        "        pooled_output = outputs[0][:, 0]  # Extract the pooled output of the first token\n",
        "        prediction = self.linear(pooled_output)\n",
        "        return prediction.view(-1)\n",
        "\n",
        "\n",
        "# Define custom dataset class\n",
        "# Instantiate the model\n",
        "model = DistilBERTRegression()\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Directory for storing training outputs\n",
        "    num_train_epochs=3,  # Number of epochs for training\n",
        "    per_device_train_batch_size=8,  # Batch size for training\n",
        "    per_device_eval_batch_size=8,  # Batch size for evaluation\n",
        "    save_steps=-1,  # Number of steps to save model checkpoint\n",
        "    save_total_limit=2,  # Limit on the total number of saved checkpoints\n",
        "    prediction_loss_only=True,  # Compute only prediction loss, not other losses\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=500,  # Number of steps for logging\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
        "    metric_for_best_model='eval_loss',  # Metric for selecting the best model\n",
        "    greater_is_better=False  # Whether a greater value of the metric is better or not\n",
        ")\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer)\n",
        "# Load and preprocess your training and validation data\n",
        "# input_ids, attention_masks, and labels are assumed to be preprocessed and ready to use\n",
        "batch_size = 16\n",
        "# Create data loaders\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)\n",
        "#print(input_ids.shape)\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "# Define optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)  # AdamW optimizer\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)  # Learning rate scheduler\n",
        "\n",
        "# Define loss function\n",
        "loss_function = nn.L1Loss()\n",
        "\n",
        "# Define function for computing mean absolute error\n",
        "def compute_mae(predictions, labels):\n",
        "    return mean_absolute_error(predictions.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
        "\n",
        "# Training loop\n",
        "best_val_mae = float('inf')  # Initialize best validation mean absolute error\n",
        "for epoch in range(training_args.num_train_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        predictions = model(input_ids, attention_mask)  # Forward pass\n",
        "        loss = loss_function(predictions, labels)  # Compute loss # Problem is in the shape of predictions and self.Linear\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        train_loss += loss.item()  # Accumulate training loss\n",
        "\n",
        "    train_loss /= len(train_dataloader)  # Compute average training loss\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0\n",
        "    val_predictions = []\n",
        "    val_labels = []\n",
        "    for batch in val_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            predictions = model(input_ids, attention_mask)  # Forward pass\n",
        "            loss = loss_function(predictions, labels)  # Compute loss\n",
        "\n",
        "        val_loss += loss.item()  # Accumulate validation loss\n",
        "        val_predictions.extend(predictions.detach().cpu().numpy())  # Collect predictions\n",
        "        val_labels.extend(labels.detach().cpu().numpy())  # Collect labels\n",
        "\n",
        "    val_loss /= len(val_dataloader)  # Compute average validation loss\n",
        "    val_mae = compute_mae(torch.tensor(val_predictions), torch.tensor(val_labels))  # Compute validation mean absolute error\n",
        "\n",
        "    # Update best validation mean absolute error and save model checkpoint\n",
        "    if val_mae < best_val_mae:\n",
        "        best_val_mae = val_mae\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # Save best model checkpoint\n",
        "\n",
        "    print(f'Epoch {epoch + 1}:')\n",
        "    print(f'Training Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f} | Validation MAE: {val_mae:.4f}')\n",
        "    print('----------------------------------------')\n",
        "\n",
        "    scheduler.step()  # Update learning rate scheduler\n",
        "\n",
        "print('Training completed successfully!')\n",
        "\n",
        "# Load the best model checkpoint\n",
        "best_model = DistilBERTRegression()\n",
        "best_model.load_state_dict(torch.load('best_model.pth'))\n",
        "best_model.to(device)\n",
        "\n",
        "# Use the best model for inference\n",
        "# ...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhCG3MPs5N6W",
        "outputId": "46501c1b-b5c6-4988-f4ab-90484f32b99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fbc4b990a90>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHVIF4vYm5aN",
        "outputId": "40ecdb71-e6c4-4278-fb97-671ff2fd4878"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([101,\n",
              "  2821,\n",
              "  2213,\n",
              "  2047,\n",
              "  2259,\n",
              "  28799,\n",
              "  6178,\n",
              "  11756,\n",
              "  4345,\n",
              "  2566,\n",
              "  29278,\n",
              "  4383,\n",
              "  22953,\n",
              "  9077,\n",
              "  3237,\n",
              "  5898,\n",
              "  6007,\n",
              "  2005,\n",
              "  2273,\n",
              "  102],\n",
              " 1338.5826758)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_input_ids[0],train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_1QSxfyqBUj",
        "outputId": "08e5099a-06cc-49b8-f7d7-0d8fe9e0902f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8000,)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "Pt1lrvCsmdOm",
        "outputId": "c642b050-9deb-463f-9115-644554f6cf73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89870cee-7370-4852-848a-c57366094e09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>621456</th>\n",
              "      <td>976641</td>\n",
              "      <td>Fly Racing Two-Piece Rain Suit (XXXXX-Large) (...</td>\n",
              "      <td>Two-piece pant / jacket rain suit featuring hi...</td>\n",
              "      <td>Two-piece pant / jacket rain suit featuring hi...</td>\n",
              "      <td>8040</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1673737</th>\n",
              "      <td>1837214</td>\n",
              "      <td>ECCPP ABS Spoiler Wing Unpainted Rear Window R...</td>\n",
              "      <td>[[FITMENT] Honda Civic 4-door 1.8L DX Sedan,[W...</td>\n",
              "      <td>&lt;b&gt;ECCPP provides many types of auto parts and...</td>\n",
              "      <td>7551</td>\n",
              "      <td>5098.425192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867132</th>\n",
              "      <td>1796993</td>\n",
              "      <td>2020 Upgraded AirPods Pro Case, KMMIN Seamless...</td>\n",
              "      <td>[[ORIGINAL UNGRADED DESIGN] - Unique specially...</td>\n",
              "      <td>Have you misplaced one of your earhud in a jea...</td>\n",
              "      <td>1814</td>\n",
              "      <td>385.826771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492668</th>\n",
              "      <td>2675710</td>\n",
              "      <td>Vayuna Silk Solid Blackout Stainless Steel Rin...</td>\n",
              "      <td>[Product Name : Blackout Curtains For Window A...</td>\n",
              "      <td>About Vayuna Invite Vayuna products into your ...</td>\n",
              "      <td>1649</td>\n",
              "      <td>8385.826763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11762</th>\n",
              "      <td>1202129</td>\n",
              "      <td>INGEAR Crochet Casual Dress Embroidery Summer ...</td>\n",
              "      <td>[This Swimsuit cover up for women is made of s...</td>\n",
              "      <td>This beautiful umbrella print dress is soft to...</td>\n",
              "      <td>2986</td>\n",
              "      <td>1250.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89870cee-7370-4852-848a-c57366094e09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89870cee-7370-4852-848a-c57366094e09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89870cee-7370-4852-848a-c57366094e09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         PRODUCT_ID                                              TITLE  \\\n",
              "621456       976641  Fly Racing Two-Piece Rain Suit (XXXXX-Large) (...   \n",
              "1673737     1837214  ECCPP ABS Spoiler Wing Unpainted Rear Window R...   \n",
              "867132      1796993  2020 Upgraded AirPods Pro Case, KMMIN Seamless...   \n",
              "492668      2675710  Vayuna Silk Solid Blackout Stainless Steel Rin...   \n",
              "11762       1202129  INGEAR Crochet Casual Dress Embroidery Summer ...   \n",
              "\n",
              "                                             BULLET_POINTS  \\\n",
              "621456   Two-piece pant / jacket rain suit featuring hi...   \n",
              "1673737  [[FITMENT] Honda Civic 4-door 1.8L DX Sedan,[W...   \n",
              "867132   [[ORIGINAL UNGRADED DESIGN] - Unique specially...   \n",
              "492668   [Product Name : Blackout Curtains For Window A...   \n",
              "11762    [This Swimsuit cover up for women is made of s...   \n",
              "\n",
              "                                               DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
              "621456   Two-piece pant / jacket rain suit featuring hi...             8040   \n",
              "1673737  <b>ECCPP provides many types of auto parts and...             7551   \n",
              "867132   Have you misplaced one of your earhud in a jea...             1814   \n",
              "492668   About Vayuna Invite Vayuna products into your ...             1649   \n",
              "11762    This beautiful umbrella print dress is soft to...             2986   \n",
              "\n",
              "         PRODUCT_LENGTH  \n",
              "621456       100.000000  \n",
              "1673737     5098.425192  \n",
              "867132       385.826771  \n",
              "492668      8385.826763  \n",
              "11762       1250.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dropped.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ox4sbR_dxVM",
        "outputId": "373943bb-a6f2-426a-a004-585dfb3d8b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.CustomDataset object at 0x7fbc48fb9ac0>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQzhR9NoIcqB"
      },
      "outputs": [],
      "source": [
        "tensorboard --logdir=./logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5Mw0pl69FG"
      },
      "source": [
        "### BERT Model Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "!wget https://github.com/adityamavle/Amazon-ML-Challenge/blob/main/pre-proccessed.zip?raw=true -O AmazonChallenge23Cleaned\n",
        "zip_ref = zipfile.ZipFile(\"AmazonChallenge23Cleaned\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-zbxHlmhEyb",
        "outputId": "85c4d8c2-3038-4da2-93c0-dc16b50519bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-23 09:44:29--  https://github.com/adityamavle/Amazon-ML-Challenge/blob/main/pre-proccessed.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/adityamavle/Amazon-ML-Challenge/raw/main/pre-proccessed.zip [following]\n",
            "--2023-04-23 09:44:30--  https://github.com/adityamavle/Amazon-ML-Challenge/raw/main/pre-proccessed.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/adityamavle/Amazon-ML-Challenge/main/pre-proccessed.zip [following]\n",
            "--2023-04-23 09:44:30--  https://raw.githubusercontent.com/adityamavle/Amazon-ML-Challenge/main/pre-proccessed.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19820165 (19M) [application/zip]\n",
            "Saving to: ‘AmazonChallenge23Cleaned’\n",
            "\n",
            "AmazonChallenge23Cl 100%[===================>]  18.90M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-23 09:44:30 (137 MB/s) - ‘AmazonChallenge23Cleaned’ saved [19820165/19820165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "y4MjkJRR_sXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/pre-proccessed (1).csv')\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "aLbqk90XNP3O",
        "outputId": "7ff7612a-fef5-4c0e-a738-2a85a6f19194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  PRODUCT_ID                                              TITLE  \\\n",
              "0     1740317     2393940  Wobit Covers® - Yamaha YZF R1M New BS6 Water R...   \n",
              "1     1511738     2369752  Golden Cart Vertical Garden Artifical Mat with...   \n",
              "2      294232     1010041   ARIAT Men's Logo Softshell Jacket, Black, Medium   \n",
              "3     2032819     2496499  Ayesha Handloom Shaggy Carpet Plain Fur Rugs f...   \n",
              "4     1042207     2302998  (Renewed) Dell Optiplex 380 Intel Core 2 Duo D...   \n",
              "\n",
              "                                       BULLET_POINTS  \\\n",
              "0  Wheeler,Resistant,Fabric,protection,Cover,Vehi...   \n",
              "1  5,QUANTITY,SIZE,Pieces,AREA,COVERAGE,ARTIFICIA...   \n",
              "2  Wind,collar,water,resistance,Stain,repellent,W...   \n",
              "3  soft,rug,Luxurious,Ideal,2,Height,Ultra,Thickn...   \n",
              "4  Intel,password,2,HDD,Enhanced,Technology,Bit,U...   \n",
              "\n",
              "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
              "0  customer,Dear,carefully,read,complete,descript...             7682   \n",
              "1  Cart,Wall,Golden,background,Small,Grass,live,A...             1591   \n",
              "2  wear,team,jacket,equestrian,athlete,aspires,zi...             2848   \n",
              "3  room,Fluffy,rug,beauty,unbelievable,perfect,sp...             1636   \n",
              "4  Renewed,Amazon,duct,original,functional,purcha...            10449   \n",
              "\n",
              "   PRODUCT_LENGTH                                       NUMERIC_DATA  \n",
              "0      984.251967                                                NaN  \n",
              "1     1614.173227  2 ,2 ,50cm,50cm,5cm,5,5 ,50cm,50cm,5cm,13.45 ,...  \n",
              "2     2600.000000                                                NaN  \n",
              "3     2362.204722                                         2 Inch,2 ,  \n",
              "4     1450.000000                            380 ,2 ,8 ,1 ,2 ,7200 ,  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcf41749-09b5-4d8c-b249-17971b77a9a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>BULLET_POINTS</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>PRODUCT_TYPE_ID</th>\n",
              "      <th>PRODUCT_LENGTH</th>\n",
              "      <th>NUMERIC_DATA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1740317</td>\n",
              "      <td>2393940</td>\n",
              "      <td>Wobit Covers® - Yamaha YZF R1M New BS6 Water R...</td>\n",
              "      <td>Wheeler,Resistant,Fabric,protection,Cover,Vehi...</td>\n",
              "      <td>customer,Dear,carefully,read,complete,descript...</td>\n",
              "      <td>7682</td>\n",
              "      <td>984.251967</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1511738</td>\n",
              "      <td>2369752</td>\n",
              "      <td>Golden Cart Vertical Garden Artifical Mat with...</td>\n",
              "      <td>5,QUANTITY,SIZE,Pieces,AREA,COVERAGE,ARTIFICIA...</td>\n",
              "      <td>Cart,Wall,Golden,background,Small,Grass,live,A...</td>\n",
              "      <td>1591</td>\n",
              "      <td>1614.173227</td>\n",
              "      <td>2 ,2 ,50cm,50cm,5cm,5,5 ,50cm,50cm,5cm,13.45 ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>294232</td>\n",
              "      <td>1010041</td>\n",
              "      <td>ARIAT Men's Logo Softshell Jacket, Black, Medium</td>\n",
              "      <td>Wind,collar,water,resistance,Stain,repellent,W...</td>\n",
              "      <td>wear,team,jacket,equestrian,athlete,aspires,zi...</td>\n",
              "      <td>2848</td>\n",
              "      <td>2600.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2032819</td>\n",
              "      <td>2496499</td>\n",
              "      <td>Ayesha Handloom Shaggy Carpet Plain Fur Rugs f...</td>\n",
              "      <td>soft,rug,Luxurious,Ideal,2,Height,Ultra,Thickn...</td>\n",
              "      <td>room,Fluffy,rug,beauty,unbelievable,perfect,sp...</td>\n",
              "      <td>1636</td>\n",
              "      <td>2362.204722</td>\n",
              "      <td>2 Inch,2 ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1042207</td>\n",
              "      <td>2302998</td>\n",
              "      <td>(Renewed) Dell Optiplex 380 Intel Core 2 Duo D...</td>\n",
              "      <td>Intel,password,2,HDD,Enhanced,Technology,Bit,U...</td>\n",
              "      <td>Renewed,Amazon,duct,original,functional,purcha...</td>\n",
              "      <td>10449</td>\n",
              "      <td>1450.000000</td>\n",
              "      <td>380 ,2 ,8 ,1 ,2 ,7200 ,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcf41749-09b5-4d8c-b249-17971b77a9a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcf41749-09b5-4d8c-b249-17971b77a9a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcf41749-09b5-4d8c-b249-17971b77a9a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRUEq9dxRNIL",
        "outputId": "35674900-0730-41ea-c3f9-47f066d2dc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0             0\n",
              "PRODUCT_ID             0\n",
              "TITLE                  0\n",
              "BULLET_POINTS        224\n",
              "DESCRIPTION          159\n",
              "PRODUCT_TYPE_ID        0\n",
              "PRODUCT_LENGTH         0\n",
              "NUMERIC_DATA       10155\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZP1-J2KSIK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9758c113-ba2c-47c4-a2c6-3465386312d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0         0\n",
              "PRODUCT_ID         0\n",
              "TITLE              0\n",
              "BULLET_POINTS      0\n",
              "DESCRIPTION        0\n",
              "PRODUCT_TYPE_ID    0\n",
              "PRODUCT_LENGTH     0\n",
              "NUMERIC_DATA       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#train = pd.read_csv('/content/pre-processed.csv')\n",
        "train_dropped_1 = train.dropna()\n",
        "train_dropped = train_dropped_1.sample(n=70000, random_state=52)\n",
        "train_dropped.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dropped = train_dropped.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "dK-WxP3xak5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dropped_1.to_csv('dropped_train.csv')\n"
      ],
      "metadata": {
        "id": "EP8quOY-hO1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BHI6QKL7n6d",
        "outputId": "97d30afe-ba08-4726-881f-2a41b3720091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_text = train_dropped['TITLE'] + ' [CLS] ' + train_dropped['BULLET_POINTS'] + ' [CLS] ' + train_dropped['DESCRIPTION'] +  ' [SEP]'\n",
        "mergd = merged_text.tolist()\n",
        "mergd[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "KX-Aa5FZEu80",
        "outputId": "25ad494b-edde-4f19-bd79-28af328a3955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jioeuinly Case for Cricket Icon 3 / ATT Motivate 2 / Cricket Splendor 4G LTE Phone Case Cover + [2 Pack] Film Soft TPU Screen Protector Blue [CLS] Cover,Film,Case,3,Soft,TPU,Pack,Phone,Screen,Cricket,ATT,Splendor,LTE,Icon,Motivate,Protector,jioeuinly,protection,equipment,Blue,Soft, [CLS] Pack,3,ATT,Splendor,LTE,Cover,Film,Blue,Case,Cricket,Icon,Motivate,Phone,Soft,TPU,Screen,Protector,jioeuinly, [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropd = train_dropped['BULLET_POINTS'].tolist()\n",
        "dropd[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bGgfJHW0FI57",
        "outputId": "56d160c0-7dd3-47e4-dfe9-edff42853324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cover,Film,Case,3,Soft,TPU,Pack,Phone,Screen,Cricket,ATT,Splendor,LTE,Icon,Motivate,Protector,jioeuinly,protection,equipment,Blue,Soft,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx9tRAvO7DUH"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "desc_title = train_dropped['DESCRIPTION'] + ' [SEP] ' + train_dropped['TITLE']\n",
        "\n",
        "# Concatenate all four columns to create 'merged_text'\n",
        "title_bullet_points = train_dropped['TITLE'] + ' [SEP] ' + train_dropped['BULLET_POINTS']\n",
        "bullet_points_description = train_dropped['BULLET_POINTS'] + ' [SEP] ' + train_dropped['DESCRIPTION']\n",
        "merged_text = title_bullet_points + ' [CLS] ' + bullet_points_description + ' [CLS] ' + desc_title\n",
        "mergd = merged_text.tolist()\n",
        "encoded_corpus = tokenizer(text=mergd,\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first',\n",
        "                            max_length=300,\n",
        "                            return_attention_mask=True)\n",
        "input_ids = encoded_corpus['input_ids']\n",
        "attention_mask = encoded_corpus['attention_mask']\n",
        "# merged_text = train_dropped['TRAIN'] + ' [CLS] ' + train_dropped['BULLET_POINTS'] + ' [CLS] ' + train_dropped['DESCRIPTION']\n",
        "\n",
        "# X = X_text.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJK3gDHEGfux",
        "outputId": "ec12371c-710c-4a71-8c56-76143179a284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 10147, 8913, 20023, 2135, 2553, 2005, 4533, 12696, 1017, 1013, 2012, 2102, 9587, 29068, 3686, 1016, 1013, 4533, 11867, 7770, 7983, 1018, 2290, 8318, 2063, 3042, 2553, 3104, 1009, 1031, 1016, 5308, 1033, 2143, 3730, 1056, 14289, 3898, 16167, 2630, 102, 3104, 1010, 2143, 1010, 2553, 1010, 1017, 1010, 3730, 1010, 1056, 14289, 1010, 5308, 1010, 3042, 1010, 3898, 1010, 4533, 1010, 2012, 2102, 1010, 11867, 7770, 7983, 1010, 8318, 2063, 1010, 12696, 1010, 9587, 29068, 3686, 1010, 16167, 1010, 10147, 8913, 20023, 2135, 1010, 3860, 1010, 3941, 1010, 2630, 1010, 3730, 1010, 101, 3104, 1010, 2143, 1010, 2553, 1010, 1017, 1010, 3730, 1010, 1056, 14289, 1010, 5308, 1010, 3042, 1010, 3898, 1010, 4533, 1010, 2012, 2102, 1010, 11867, 7770, 7983, 1010, 8318, 2063, 1010, 12696, 1010, 9587, 29068, 3686, 1010, 16167, 1010, 10147, 8913, 20023, 2135, 1010, 3860, 1010, 3941, 1010, 2630, 1010, 3730, 1010, 102, 5308, 1010, 1017, 1010, 2012, 2102, 1010, 11867, 7770, 7983, 1010, 8318, 2063, 1010, 3104, 1010, 2143, 1010, 2630, 1010, 2553, 1010, 4533, 1010, 12696, 1010, 9587, 29068, 3686, 1010, 3042, 1010, 3730, 1010, 1056, 14289, 1010, 3898, 1010, 16167, 1010, 10147, 8913, 20023, 2135, 1010, 101, 5308, 1010, 1017, 1010, 2012, 2102, 1010, 11867, 7770, 7983, 1010, 8318, 2063, 1010, 3104, 1010, 2143, 1010, 2630, 1010, 2553, 1010, 4533, 1010, 12696, 1010, 9587, 29068, 3686, 1010, 3042, 1010, 3730, 1010, 1056, 14289, 1010, 3898, 1010, 16167, 1010, 10147, 8913, 20023, 2135, 1010, 102, 10147, 8913, 20023, 2135, 2553, 2005, 4533, 12696, 1017, 1013, 2012, 2102, 9587, 29068, 3686, 1016, 1013, 4533, 11867, 7770, 7983, 1018, 2290, 8318, 2063, 3042, 2553, 3104, 1009, 1031, 1016, 5308, 1033, 2143, 3730, 1056, 14289, 3898, 16167, 2630, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U91GKKNoKkc7"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# def filter_long_descriptions(tokenizer, descriptions, max_len):\n",
        "#     indices = []\n",
        "#     lengths = tokenizer(descriptions, padding=False,\n",
        "#                      truncation=False, return_length=True)['length']\n",
        "#     for i in range(len(descriptions)):\n",
        "#         if lengths[i] <= max_len-2:\n",
        "#             indices.append(i)\n",
        "#     return indices\n",
        "# short_descriptions = filter_long_descriptions(tokenizer,\n",
        "#                               #  mergd, 300)\n",
        "input_ids = np.array(input_ids)\n",
        "attention_mask = np.array(attention_mask)\n",
        "labels = train_dropped['PRODUCT_LENGTH'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sze2nVSkK4QS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_size = 0.1\n",
        "seed = 42\n",
        "train_inputs, test_inputs, train_labels, test_labels = \\\n",
        "            train_test_split(input_ids, labels, test_size=test_size,\n",
        "                             random_state=seed)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_mask,\n",
        "                                        labels, test_size=test_size,\n",
        "                                        random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQYU4bkKQOk"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# price_scaler = StandardScaler()\n",
        "# price_scaler.fit(train_labels.reshape(-1, 1))\n",
        "# train_labels = price_scaler.transform(train_labels.reshape(-1, 1))\n",
        "# test_labels = price_scaler.transform(test_labels.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0L5iLua_VGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdabb3a-a007-44eb-ac83-243c1c8b91a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDKElzFz9OvU"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# batch_size = 16\n",
        "# def create_dataloaders(inputs, masks, labels, batch_size=16):\n",
        "#     input_tensor = torch.tensor(inputs)\n",
        "#     mask_tensor = torch.tensor(masks)\n",
        "#     labels_tensor = torch.tensor(labels)\n",
        "#     dataset = TensorDataset(input_tensor, mask_tensor,\n",
        "#                             labels_tensor)\n",
        "#     dataloader = DataLoader(dataset, batch_size=16,\n",
        "#                             shuffle=True)\n",
        "#     return dataloader\n",
        "# train_dataloader = create_dataloaders(train_input_ids, train_attention_masks, train_labels)\n",
        "# test_dataloader = create_dataloaders(val_input_ids, val_attention_masks, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INp_FeRDLEVB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 16\n",
        "def create_dataloaders(inputs, masks, labels, batch_size):\n",
        "    input_tensor = torch.tensor(inputs)\n",
        "    mask_tensor = torch.tensor(masks)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_tensor, mask_tensor,\n",
        "                            labels_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "    return dataloader\n",
        "train_dataloader = create_dataloaders(train_inputs, train_masks,\n",
        "                                      train_labels, batch_size)\n",
        "test_dataloader = create_dataloaders(test_inputs, test_masks,\n",
        "                                     test_labels, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "def create_dataset(inputs, masks, labels, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((inputs, masks, labels))\n",
        "    dataset = dataset.shuffle(len(inputs)).batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = create_dataset(train_inputs, train_masks, train_labels, batch_size)\n",
        "test_dataset = create_dataset(test_inputs, test_masks, test_labels, batch_size)"
      ],
      "metadata": {
        "id": "g6uImSR2gV0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C02t6wHFOWtI"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# from transformers import BertModel\n",
        "\n",
        "# class BertRegressor(nn.Module):\n",
        "#     def __init__(self, drop_rate=0.2, freeze_bert=False):\n",
        "#         super(BertRegressor, self).__init__()\n",
        "#         D_in, D_out = 768, 1\n",
        "#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "#         self.regressor = nn.Sequential(\n",
        "#             nn.Dropout(drop_rate),\n",
        "#             nn.Linear(D_in, D_out))\n",
        "\n",
        "#     def forward(self, input_ids, attention_masks):\n",
        "#         outputs = self.bert(input_ids, attention_mask=attention_masks)\n",
        "#         class_label_output = outputs[1]\n",
        "#         outputs = self.regressor(class_label_output)\n",
        "#         return outputs\n",
        "\n",
        "# model = BertRegressor(drop_rate=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8gsVMiFTJLc"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# from transformers import MobileBertModel\n",
        "\n",
        "# class MobileBertRegressor(nn.Module):\n",
        "#     def __init__(self, drop_rate=0.2, freeze_mobilebert=False):\n",
        "#         super(MobileBertRegressor, self).__init__()\n",
        "#         D_in, D_out = 512, 1  # Update input and output dimensions for MobileBertModel\n",
        "#         self.mobilebert = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n",
        "#         self.regressor = nn.Sequential(\n",
        "#             nn.Dropout(drop_rate),\n",
        "#             nn.Linear(D_in, D_out))\n",
        "\n",
        "#         # Freeze MobileBertModel if specified\n",
        "#         if freeze_mobilebert:\n",
        "#             for param in self.mobilebert.parameters():\n",
        "#                 param.requires_grad = False\n",
        "\n",
        "#     def forward(self, input_ids, attention_masks):\n",
        "#         outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_masks)\n",
        "#         class_label_output = outputs[1]  # Use the second element of the outputs tuple as the pooled output\n",
        "#         outputs = self.regressor(class_label_output)\n",
        "#         return outputs\n",
        "\n",
        "# # Example usage\n",
        "# model = MobileBertRegressor(drop_rate=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "# from transformers import DistilBertModel\n",
        "\n",
        "# class DistilBertRegressor(nn.Module):\n",
        "#     def __init__(self, drop_rate=0.2, freeze_distilbert=False):\n",
        "#         super(DistilBertRegressor, self).__init__()\n",
        "#         D_in, D_out = 768, 1  # Update input and output dimensions for DistilBertModel\n",
        "#         self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "#         self.regressor = nn.Sequential(\n",
        "#             nn.Dropout(drop_rate),\n",
        "#             nn.Linear(D_in, D_out))\n",
        "\n",
        "#         # Freeze DistilBertModel if specified\n",
        "#         if freeze_distilbert:\n",
        "#             for param in self.distilbert.parameters():\n",
        "#                 param.requires_grad = False\n",
        "\n",
        "#     def forward(self, input_ids, attention_masks):\n",
        "#         outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_masks)\n",
        "#         class_label_output = outputs[0][:, 0]  # Use the first element of the outputs tuple and take the first token [CLS] representation as the pooled output\n",
        "#         outputs = self.regressor(class_label_output)\n",
        "#         return outputs\n",
        "\n",
        "# # Example usage\n",
        "# model = DistilBertRegressor(drop_rate=0.2)"
      ],
      "metadata": {
        "id": "arXWYKfZLiam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCymJ46yiQJd",
        "outputId": "4f2d752b-560e-45eb-9d89-3b92424186ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(16, 300), dtype=int64, numpy=\n",
              " array([[  101,  5631,  3509, ...,     0,     0,     0],\n",
              "        [  101,  2553,  7529, ...,     0,     0,     0],\n",
              "        [  101,  7861, 19279, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  2190, 27072, ...,     0,     0,     0],\n",
              "        [  101, 16420,  2232, ...,     0,     0,     0],\n",
              "        [  101, 24665, 16530, ...,     0,     0,     0]])>,\n",
              " <tf.Tensor: shape=(16, 300), dtype=int64, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
              " <tf.Tensor: shape=(16,), dtype=float64, numpy=\n",
              " array([ 196.8503935 ,  551.1811018 ,  200.        ,  100.        ,\n",
              "         393.700787  , 1377.9527545 ,  700.        , 1400.        ,\n",
              "         708.6614166 ,  669.29      , 2799.99999714,  393.700787  ,\n",
              "         800.        ,  590.5511805 , 1889.7637776 ,  393.700787  ])>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import MobileBertModel\n",
        "\n",
        "class MobileBertRegressor(nn.Module):\n",
        "    def __init__(self, drop_rate=0.5, freeze_mobilebert=False):\n",
        "        super(MobileBertRegressor, self).__init__()\n",
        "        D_in, D_out = 512, 1  # Update input and output dimensions for MobileBertModel\n",
        "        self.mobilebert = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(D_in, D_out))\n",
        "\n",
        "        # Freeze MobileBertModel if specified\n",
        "        if freeze_mobilebert:\n",
        "            for param in self.mobilebert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_masks)\n",
        "        class_label_output = outputs[1]  # Use the second element of the outputs tuple as the pooled output\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "\n",
        "# Example usage\n",
        "model = MobileBertRegressor(drop_rate=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3iQ_PYgDZXr",
        "outputId": "7dea637d-41b6-4534-a721-2597208d269e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight']\n",
            "- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "class MobileBertRegressor(tf.keras.Model):\n",
        "    def __init__(self, drop_rate=0.5, freeze_mobilebert=False):\n",
        "        super(MobileBertRegressor, self).__init__()\n",
        "        D_in, D_out = 512, 1  # Update input and output dimensions for MobileBertModel\n",
        "        self.mobilebert = TFAutoModel.from_pretrained('google/mobilebert-uncased')\n",
        "        self.regressor = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(1,input_shape=(D_in))\n",
        "\n",
        "            tf.keras.layers.Dropout(drop_rate),\n",
        "            tf.keras.layers.Dense(D_out)\n",
        "        ])\n",
        "\n",
        "        # Freeze MobileBertModel if specified\n",
        "        if freeze_mobilebert:\n",
        "            self.mobilebert.trainable = False\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        # Compute MobileBERT hidden states\n",
        "        outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        class_label_output = outputs[1]  # Use the second element of the outputs tuple as the pooled output\n",
        "\n",
        "        # Pass through the regression layer\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "\n",
        "# Example usage\n",
        "model = MobileBertRegressor(drop_rate=0.5)\n"
      ],
      "metadata": {
        "id": "GcsEOsSocDMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "class TFMobileBertRegressor(tf.keras.Model):\n",
        "    def __init__(self, drop_rate=0.5, freeze_mobilebert=True):\n",
        "        super(TFMobileBertRegressor, self).__init__()\n",
        "        D_in,D_out=512,1\n",
        "        self.mobilebert = TFAutoModel.from_pretrained('google/mobilebert-uncased')\n",
        "        self.regressor = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dropout(drop_rate),\n",
        "            tf.keras.layers.Dense(256, activation='relu',input_shape=(D_in,)),\n",
        "            tf.keras.layers.Dropout(drop_rate),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dropout(drop_rate),\n",
        "            tf.keras.layers.Dense(D_out)\n",
        "        ])\n",
        "\n",
        "        # Freeze MobileBERT layers if specified\n",
        "        if freeze_mobilebert:\n",
        "            self.mobilebert.trainable = False\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_masks = inputs\n",
        "        outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_masks)\n",
        "        class_label_output = outputs[1]  # Use the second element of the outputs tuple as the pooled output\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "tf_model = TFMobileBertRegressor(drop_rate=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK9flQQ6ei_J",
        "outputId": "f3545007-9394-4967-9e42-41efd9f510d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertModel: ['predictions___cls', 'seq_relationship___cls']\n",
            "- This IS expected if you are initializing TFMobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFMobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFMobileBertModel were initialized from the model checkpoint at google/mobilebert-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V5W5GEI9-m9",
        "outputId": "289ba514-2947-4462-de96-87a27a91b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileBertRegressor(\n",
              "  (mobilebert): MobileBertModel(\n",
              "    (embeddings): MobileBertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 512)\n",
              "      (token_type_embeddings): Embedding(2, 512)\n",
              "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
              "      (LayerNorm): NoNorm()\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): MobileBertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x MobileBertLayer(\n",
              "          (attention): MobileBertAttention(\n",
              "            (self): MobileBertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): MobileBertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): NoNorm()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): MobileBertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (intermediate_act_fn): ReLU()\n",
              "          )\n",
              "          (output): MobileBertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): NoNorm()\n",
              "            (bottleneck): OutputBottleneck(\n",
              "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (LayerNorm): NoNorm()\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (bottleneck): Bottleneck(\n",
              "            (input): BottleneckLayer(\n",
              "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (LayerNorm): NoNorm()\n",
              "            )\n",
              "            (attention): BottleneckLayer(\n",
              "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (LayerNorm): NoNorm()\n",
              "            )\n",
              "          )\n",
              "          (ffn): ModuleList(\n",
              "            (0-2): 3 x FFNLayer(\n",
              "              (intermediate): MobileBertIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): ReLU()\n",
              "              )\n",
              "              (output): FFNOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (LayerNorm): NoNorm()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): MobileBertPooler()\n",
              "  )\n",
              "  (regressor): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU.\")\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_JRplzC-KoE",
        "outputId": "cf110668-edea-4f6d-ebf6-1ef2abc8dd37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=0.001,\n",
        "                  eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKI4nADx-NUL",
        "outputId": "279ee2b2-c102-4158-ded5-d651b7c7b192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7876\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                 num_warmup_steps=0, num_training_steps=total_steps)\n",
        "print(total_steps)\n",
        "loss_function = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7-7nKntO2hO",
        "outputId": "5cdb9020-e5bb-4022-9e69-8b528da5120e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3938"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W51OWmo_-TQl",
        "outputId": "d460699d-a943-499b-b1a2-3c5fd0392a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "-----\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-1b2d0dff6f96>:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(model.parameters(), clip_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "def train(model, optimizer, scheduler, loss_function, epochs,\n",
        "          train_dataloader, device, clip_value=2):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        print(\"-----\")\n",
        "        best_loss = 1e10\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            print(step)\n",
        "            batch_inputs, batch_masks, batch_labels = \\\n",
        "             tuple(b.to(device) for b in batch)\n",
        "            model.zero_grad()\n",
        "            outputs = model(batch_inputs, batch_masks)\n",
        "            loss = loss_function(outputs.squeeze(),\n",
        "                             batch_labels.squeeze())\n",
        "            loss.backward()\n",
        "            clip_grad_norm(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "    return model\n",
        "model = train(tf_model, optimizer, scheduler, loss_function, epochs,\n",
        "              train_dataloader, device, clip_value=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=1e-8)\n",
        "\n",
        "def create_learning_rate_scheduler(total_steps, warmup_steps):\n",
        "    \"\"\"\n",
        "    Create a linear learning rate scheduler with warmup.\n",
        "    \"\"\"\n",
        "    def scheduler(epoch):\n",
        "        if epoch < warmup_steps:\n",
        "            return (epoch + 1) / warmup_steps\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "    return tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "epochs = 2\n",
        "batch_size = 16  # Update with your desired batch size\n",
        "total_steps = (len(train_dataset) // batch_size) * epochs\n",
        "warmup_steps = 0  # Set warmup to 10% of total steps\n",
        "loss_function = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "def train(model, optimizer, loss_function, epochs, train_dataset, clip_value=2):\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch:\", epoch + 1)\n",
        "        best_loss = 1e10\n",
        "        for step, batch in enumerate(train_dataset):\n",
        "            print(\"Step:\", step + 1)\n",
        "            batch_inputs, batch_masks, batch_labels = batch\n",
        "            with tf.GradientTape() as tape:\n",
        "                outputs = model((batch_inputs, batch_masks), training=True)\n",
        "                loss = loss_function(tf.squeeze(outputs), tf.squeeze(batch_labels))\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, clip_value)\n",
        "            optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))\n",
        "\n",
        "    return model\n",
        "\n",
        "#model = MobileBertRegressor(D_in, D_out, drop_rate=0.5, freeze_mobilebert=False)\n",
        "train(tf_model, optimizer, loss_function, epochs, train_dataset, clip_value=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoxGZa--f5H8",
        "outputId": "0c8e8006-0e03-4191-b4d9-d5ee241effa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Step: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPjenC8ni6B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YUuilJkYQx5"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/dataset/train.csv')\n",
        "train_dropped = train.dropna()\n",
        "val_dropped = train_dropped.sample(n=5000,random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4sPEC7gZlbk"
      },
      "outputs": [],
      "source": [
        "encoded_val_corpus = tokenizer(text=val_dropped['TITLE'].tolist(),\n",
        "                          add_special_tokens=True,\n",
        "                          padding='max_length',\n",
        "                          truncation='longest_first',\n",
        "                          max_length=150,\n",
        "                          return_attention_mask=True)\n",
        "val_input_ids = np.array(encoded_val_corpus['input_ids'])\n",
        "val_attention_mask = np.array(encoded_val_corpus['attention_mask'])\n",
        "val_labels = val_dropped['PRODUCT_LENGTH'].to_numpy()\n",
        "print(val_labels.shape)\n",
        "val_dataloader = create_dataloaders(val_input_ids,\n",
        "                         val_attention_mask, val_labels, batch_size)\n",
        "y_pred_scaled = predict(model, val_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B2I21vRbCGg"
      },
      "outputs": [],
      "source": [
        "y_test = val_dropped['PRODUCT_LENGTH'].to_numpy()\n",
        "y_pred = price_scaler.inverse_transform(y_pred_scaled)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKSX4mm9byGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1MACBNZGasZ"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "def train(model, optimizer, scheduler, loss_function, epochs,\n",
        "          train_dataloader, device, clip_value=2):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        print(\"-----\")\n",
        "        best_loss = 1e10\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            print(step)\n",
        "            batch_inputs, batch_masks, batch_labels = [b.to(device) for b in batch]\n",
        "            model.zero_grad()\n",
        "            print('outputs error')\n",
        "            print(batch_inputs.shape)\n",
        "            print(batch_labels.shape)\n",
        "            print(batch_masks.shape)\n",
        "            outputs = model(batch_inputs,batch_masks)\n",
        "            loss = loss_function(outputs.squeeze(), batch_labels.squeeze())\n",
        "            loss.backward()\n",
        "            clip_grad_norm(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "    return model\n",
        "model = train(model, optimizer, scheduler, loss_function, epochs,\n",
        "              train_dataloader, device, clip_value=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import yeojohnson\n",
        "\n",
        "# Example numerical data\n",
        "data = np.array([-2, -1, 0, 1, 2])\n",
        "\n",
        "# Perform Yeo-Johnson transformation\n",
        "transformed_data, _ = yeojohnson(data)\n",
        "\n",
        "# Print the transformed data\n",
        "print(transformed_data)"
      ],
      "metadata": {
        "id": "kDcNkQkI7120"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dropped['PRODUCT_TYPE_ID'].head"
      ],
      "metadata": {
        "id": "iZINjymi8Nem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_data,_ = yeojohnson(train_dropped['PRODUCT_TYPE_ID'].to_numpy())"
      ],
      "metadata": {
        "id": "OXQhc02y8FTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dropped['PRODUCT_TYPE_ID'].head(20))\n",
        "print(transformed_data[0:20])"
      ],
      "metadata": {
        "id": "hkFvSdkw8p72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = ['Title', 'Review Text']\n",
        "cat_cols = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name']\n",
        "numerical_cols = ['Rating', 'Age', 'Positive Feedback Count']\n",
        "\n",
        "column_info_dict = {\n",
        "    'text_cols': text_cols,\n",
        "    'num_cols': numerical_cols,\n",
        "    'cat_cols': cat_cols,\n",
        "    'label_col': 'Recommended IND',\n",
        "    'label_list': ['Not Recommended', 'Recommended']\n",
        "}\n",
        "\n",
        "\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path='bert-base-uncased'\n",
        ")\n",
        "\n",
        "data_args = MultimodalDataTrainingArguments(\n",
        "    data_path='.',\n",
        "    combine_feat_method='gating_on_cat_and_num_feats_then_sum',\n",
        "    column_info=column_info_dict,\n",
        "    task='classification'\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./logs/model_name\",\n",
        "    logging_dir=\"./logs/runs\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    evaluate_during_training=True,\n",
        "    logging_steps=25,\n",
        "    eval_steps=250\n",
        ")\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "id": "BxrPLDMB9OKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "mJmpnEiN3Oew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a text to analyze\n",
        "text = \"The temperature is 25 degrees Celsius and the weight is 150 pounds.\"\n",
        "\n",
        "# Process the text with SpaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract numbers and units using SpaCy's named entity recognition\n",
        "numbers = []\n",
        "units = []\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ == \"QUANTITY\":  # Check if the entity is a quantity\n",
        "        number, unit = ent.text.split(\" \")  # Split the quantity into number and unit\n",
        "        numbers.append(float(number))  # Convert the number to float\n",
        "        units.append(unit)\n",
        "\n",
        "# Print the extracted numbers and units\n",
        "print(\"Numbers:\", numbers)\n",
        "print(\"Units:\", units)"
      ],
      "metadata": {
        "id": "xBGXWcRx3Rlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ner(data):\n",
        "    quantities = []\n",
        "    prices = []\n",
        "    products = []\n",
        "    for text in data:\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"QUANTITY\":  # Check if the entity is a quantity\n",
        "                quantities.append(ent.text)\n",
        "            elif ent.label_ == \"MONEY\":  # Check if the entity is a monetary value\n",
        "                prices.append(ent.text)\n",
        "            elif ent.label_ == \"PRODUCT\":  # Check if the entity is a product\n",
        "                products.append(ent.text)\n",
        "    return quantities, prices, products\n",
        "\n",
        "# Example dataset\n",
        "titles = [\"Product Title 1\", \"Product Title 2\", \"Product Title 3\"]\n",
        "descriptions = [\"Product description 1\", \"Product description 2\", \"Product description 3\"]\n",
        "bullet_points = [\"Bullet point 1\", \"Bullet point 2\", \"Bullet point 3\"]\n",
        "\n",
        "# Concatenate the data into a single list\n",
        "data = titles + descriptions + bullet_points\n",
        "\n",
        "# Extract quantities, prices, and product labels\n",
        "quantities, prices, products = extract_ner(data)\n",
        "\n",
        "# Print the extracted quantities, prices, and product labels\n",
        "print(\"Quantities:\", quantities)\n",
        "print(\"Prices:\", prices)\n",
        "print(\"Products:\", products)"
      ],
      "metadata": {
        "id": "Eo3xkAM43TS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to extract quantities, prices, and product labels\n",
        "def extract_ner(data):\n",
        "    quantities = []\n",
        "    prices = []\n",
        "    products = []\n",
        "    for text in data:\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in {\"QUANTITY\", \"MONEY\", \"PRODUCT\"}:  # Use set for faster membership testing\n",
        "                if ent.label_ == \"QUANTITY\":  # Check if the entity is a quantity\n",
        "                    quantities.append(ent.text)\n",
        "                elif ent.label_ == \"MONEY\":  # Check if the entity is a monetary value\n",
        "                    prices.append(ent.text)\n",
        "                else:  # Entity must be a product\n",
        "                    products.append(ent.text)\n",
        "    return quantities, prices, products\n",
        "\n",
        "# Example DataFrame\n",
        "# Concatenate the text columns into a single Series\n",
        "text_data = pd.concat([train_dropped[\"TITLE\"], train_dropped[\"BULLET_POINTS\"],train_dropped[\"DESCRIPTION\"]])\n",
        "\n",
        "# Extract quantities, prices, and product labels\n",
        "quantities, prices, products = extract_ner(text_data)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "quantities = np.array(quantities)\n",
        "prices = np.array(prices)\n",
        "products = np.array(products)\n",
        "\n",
        "# Print the extracted quantities, prices, and product labels\n",
        "print(\"Quantities:\", quantities)\n",
        "print(\"Prices:\", prices)\n",
        "print(\"Products:\", products)"
      ],
      "metadata": {
        "id": "i86Q1vT_5kzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a function to extract quantities, prices, and product labels\n",
        "def extract_ner(data):\n",
        "    quantities = []\n",
        "    prices = []\n",
        "    products = []\n",
        "    for doc in nlp.pipe(data, disable=[\"parser\", \"tagger\"]):  # Use SpaCy's built-in text processing pipeline\n",
        "        # Use NumPy vectorization to extract quantities, prices, and products\n",
        "        ent_labels = np.array([ent.label_ for ent in doc.ents])\n",
        "        ent_texts = np.array([ent.text for ent in doc.ents])\n",
        "\n",
        "        # Extract quantities\n",
        "        quantities_mask = ent_labels == \"QUANTITY\"\n",
        "        quantities.extend(ent_texts[quantities_mask])\n",
        "\n",
        "        # Extract prices\n",
        "        prices_mask = ent_labels == \"MONEY\"\n",
        "        prices.extend(ent_texts[prices_mask])\n",
        "\n",
        "        # Extract products\n",
        "        products_mask = ent_labels == \"PRODUCT\"\n",
        "        products.extend(ent_texts[products_mask])\n",
        "\n",
        "    return quantities, prices, products\n",
        "\n",
        "# Example DataFrame\n",
        "# Concatenate the text columns into a single Series\n",
        "text_data = pd.concat([train_dropped[\"TITLE\"], train_dropped[\"BULLET_POINTS\"], train_dropped[\"DESCRIPTION\"]])\n",
        "# Extract quantities, prices, and product labels\n",
        "quantities, prices, products = extract_ner(text_data)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "quantities = np.array(quantities)\n",
        "prices = np.array(prices)\n",
        "products = np.array(products)\n",
        "\n",
        "# Print the extracted quantities, prices, and product labels\n",
        "print(\"Quantities:\", quantities)\n",
        "print(\"Prices:\", prices)\n",
        "print(\"Products:\", products)\n"
      ],
      "metadata": {
        "id": "_I5pM9p76yUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFFN_zIm7DWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP5T0g_wTc21"
      },
      "source": [
        "### Simple Regression with distilbert tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgc6D54xTsst"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the DistilBERT model and tokenizer\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Step 2: Load and preprocess the dataset\n",
        "# Assume that the dataset is loaded into a pandas DataFrame called \"df\"\n",
        "# and that the \"bullet_points\" column contains the bullet points and \"product_length\" contains the label\n",
        "\n",
        "X = train_dropped['BULLET_POINTS'].tolist()\n",
        "y = train_dropped['PRODUCT_LENGTH'].values\n",
        "\n",
        "max_length = 512\n",
        "# Preprocess the bullet points using the tokenizer\n",
        "X_preprocessed = []\n",
        "for text in X:\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True, padding ='max_length', max_length = max_length)\n",
        "    X_preprocessed.append(input_ids)\n",
        "\n",
        "# Step 3: Convert the preprocessed bullet points into input features\n",
        "input_ids = torch.tensor(X_preprocessed)\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    embeddings = outputs[0]\n",
        "\n",
        "# Step 4: Concatenate the text embeddings for each bullet point\n",
        "X_concat = []\n",
        "for emb in embeddings:\n",
        "    X_concat.append(emb.mean(dim=0).tolist())\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Build the neural network\n",
        "import torch.nn as nn\n",
        "\n",
        "class RegressionModel(nn.Module):\n",
        "    def _init_(self, input_size, hidden_size):\n",
        "        super(RegressionModel, self)._init_()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Step 7: Train the regression model\n",
        "import torch.optim as optim\n",
        "\n",
        "model = RegressionModel(input_size=len(X_concat[0]), hidden_size=128)\n",
        "criterion = nn.MAELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(torch.tensor(X_train[i:i+batch_size]).float())\n",
        "        loss = criterion(outputs.squeeze(), torch.tensor(y_train[i:i+batch_size]).float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item() * len(X_train[i:i+batch_size])\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(X_train):.4f}')\n",
        "\n",
        "# Step 8: Evaluate the performance of the regression model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(torch.tensor(X_test).float()).squeeze().numpy()\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')\n",
        "\n",
        "# Step 9: Make predictions on new, unseen data\n",
        "# Assume that we have a new dataset loaded into a pandas DataFrame called \"new_df\"\n",
        "# and that the \"bullet_points\" column contains the bullet points we want to predict the length of\n",
        "\n",
        "# Preprocess the bullet points using the tokenizer\n",
        "X_new = trial_test['BULLET_POINTS'].tolist()\n",
        "X_new_preprocessed = []\n",
        "for text in X_new:\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "    X_new_preprocessed.append(input_ids)\n",
        "\n",
        "# Convert the preprocessed bullet points into input features\n",
        "input_ids = torch.tensor(X_new_preprocessed)\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    embeddings = outputs[0]\n",
        "\n",
        "# Concatenate the text embeddings for each bullet point\n",
        "X_new_concat = []\n",
        "for emb in embeddings:\n",
        "    X_new_concat.append(emb.mean(dim=0).tolist())\n",
        "\n",
        "# Make predictions using the trained regression model\n",
        "with torch.no_grad():\n",
        "    y_pred_new = model(torch.tensor(X_new_concat).float()).squeeze().numpy()\n",
        "\n",
        "# Print the predicted product lengths for each bullet point\n",
        "for i in range(len(trial_test)):\n",
        "    print(f'Bullet point: {X_new[i]}')\n",
        "    print(f'Predicted length: {y_pred_new[i]:.2f}')\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Crijsv-W445"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "max_length = 128\n",
        "max_seq_length = 128\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Step 2: Load and preprocess the dataset\n",
        "# Assume that the dataset is loaded into a pandas DataFrame called \"df\"\n",
        "# and that the \"bullet_points\" column contains the bullet points and \"product_length\" contains the label\n",
        "\n",
        "X = train_dropped['BULLET_POINTS'].tolist()\n",
        "y = train_dropped['PRODUCT_LENGTH'].values\n",
        "\n",
        "# Preprocess the bullet points using the tokenizer\n",
        "X_preprocessed = []\n",
        "for text in X:\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True,padding = 'max_length',max_length = max_length,truncation = True) #Truncation done\n",
        "    X_preprocessed.append(input_ids)\n",
        "    # Pad or truncate the input sequence to a fixed length\n",
        "    if len(input_ids) > max_seq_length:\n",
        "        input_ids = input_ids[:max_seq_length-1] + [tokenizer.sep_token_id]  # Truncate and add SEP token\n",
        "    else:\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5cJZudxbjVH"
      },
      "outputs": [],
      "source": [
        "len(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9y-bL0idyoz"
      },
      "outputs": [],
      "source": [
        "len(X_preprocessed[1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQMMpziugi-z"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_seq_length = 512  # or another value that matches the model's maximum sequence length\n",
        "batch_size = 64  # for example\n",
        "X_concat = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_preprocessed), batch_size):\n",
        "        input_ids = torch.tensor(X_preprocessed[i:i+batch_size]).to(device)\n",
        "        # Truncate the input sequences to the maximum sequence length\n",
        "        input_ids = input_ids[:,:max_seq_length]\n",
        "        outputs = model(input_ids)\n",
        "        embeddings = outputs[0]\n",
        "        for emb in embeddings:\n",
        "            X_concat.append(emb.mean(dim=0).tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MAofZoXf6Zi"
      },
      "outputs": [],
      "source": [
        "input_ids = torch.tensor(X_preprocessed).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzlZdj2jgkR5"
      },
      "outputs": [],
      "source": [
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CombNlhmcCN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the mean absolute percentage error (MAPE) between y_true and y_pred.\n",
        "    Args:\n",
        "        y_true (array-like): Array of true labels.\n",
        "        y_pred (array-like): Array of predicted labels.\n",
        "    Returns:\n",
        "        float: Mean absolute percentage error.\n",
        "    \"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "\n",
        "# Create some example true labels and predicted labels\n",
        "y_true = [1.2, 2.5, 3.8, 4.1, 5.3]\n",
        "y_pred = [1.0, 2.4, 4.0, 4.2, 5.2]\n",
        "\n",
        "# Calculate the mean absolute percentage error\n",
        "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "# Calculate the score using the formula\n",
        "score = max(0, 100*(1 - mape))\n",
        "\n",
        "# Print the score\n",
        "print(\"Score:\", score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEw9zX0rUL0i"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the DistilBERT model and tokenizer\n",
        " # Pad with PAD tokens\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Step 3: Convert the preprocessed bullet points into input features\n",
        "#input_ids = torch.tensor(input_ids).to(device).long()\n",
        "input_ids = torch.tensor(X_preprocessed).long()\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    embeddings = outputs[0]\n",
        "\n",
        "# Step 4: Concatenate the text embeddings for each bullet point\n",
        "X_concat = []\n",
        "for emb in embeddings:\n",
        "    X_concat.append(emb.mean(dim=0).tolist())\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Build the neural network\n",
        "import torch.nn as nn\n",
        "\n",
        "class RegressionModel(nn.Module):\n",
        "    def _init_(self, input_size, hidden_size):\n",
        "        super(RegressionModel, self)._init_()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Step 7: Train the regression model\n",
        "import torch.optim as optim\n",
        "\n",
        "model = RegressionModel(input_size=len(X_concat[0]), hidden_size=128)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(torch.tensor(X_train[i:i+batch_size]).float())\n",
        "        loss = criterion(outputs.squeeze(), torch.tensor(y_train[i:i+batch_size]).float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item() * len(X_train[i:i+batch_size])\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(X_train):.4f}')\n",
        "\n",
        "# Step 8: Evaluate the performance of the regression model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(torch.tensor(X_test).float()).squeeze().numpy()\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')\n",
        "\n",
        "# Step 9: Make predictions on new, unseen data\n",
        "# Assume that we have a new dataset loaded into a pandas DataFrame called \"new_df\"\n",
        "# and that the \"bullet_points\" column contains the bullet points we want to predict the length of\n",
        "\n",
        "# Preprocess the bullet points using the tokenizer\n",
        "X_new = trial_test['BULLET_POINTS'].tolist()\n",
        "X_new_preprocessed = []\n",
        "for text in X_new:\n",
        "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "    X_new_preprocessed.append(input_ids)\n",
        "\n",
        "# Convert the preprocessed bullet points into input features\n",
        "input_ids = torch.tensor(X_new_preprocessed)\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    embeddings = outputs.last_hidden_state\n",
        "\n",
        "# Concatenate the text embeddings for each bullet point\n",
        "X_new_concat = []\n",
        "for emb in embeddings:\n",
        "    X_new_concat.append(emb.mean(dim=0).tolist())\n",
        "\n",
        "# Make predictions using the trained regression model\n",
        "with torch.no_grad():\n",
        "    y_pred_new = model(torch.tensor(X_new_concat).float()).squeeze().numpy()\n",
        "\n",
        "# Print the predicted product lengths for each bullet point\n",
        "for i in range(len(trial_test)):\n",
        "    print(f'Bullet point: {X_new[i]}')\n",
        "    print(f'Predicted length: {y_pred_new[i]:.2f}')\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CCoVzd8YUug"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Create a DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Example input text\n",
        "input_text = \"This is an example sentence for tokenization lego batman outfits cosplay tyler durden.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
        "\n",
        "# Specify the maximum allowed sequence length\n",
        "max_seq_length = 10\n",
        "\n",
        "# Truncate or pad the input_ids token sequence to ensure it adheres to max_seq_length\n",
        "if len(input_ids) > max_seq_length:\n",
        "    input_ids = input_ids[:max_seq_length-1] + [tokenizer.sep_token_id]  # Truncate and add SEP token\n",
        "else:\n",
        "    padding_length = max_seq_length - len(input_ids)\n",
        "    input_ids = input_ids + [tokenizer.pad_token_id] * padding_length  # Pad with PAD tokens\n",
        "\n",
        "# Print the resulting input_ids token sequence\n",
        "print(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcggQ1NSTe_T"
      },
      "source": [
        "###Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0JYa6wzDavL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "corr = train['PRODUCT_TYPE_ID'].corr(train['PRODUCT_LENGTH'])\n",
        "sns.scatterplot(x='PRODUCT_TYPE_ID', y='PRODUCT_LENGTH', data=train)\n",
        "sns.regplot(x='PRODUCT_TYPE_ID', y='PRODUCT_LENGTH', data=train, scatter=False)\n",
        "plt.title(f'Correlation: {corr:.2f}')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AuB-wBwAJRDg"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}